{
  "102": {
    "inputs": {
      "image": "r_0002 (1).png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "107": {
    "inputs": {
      "strength": 1,
      "model": [
        "108",
        0
      ]
    },
    "class_type": "CFGNorm",
    "_meta": {
      "title": "CFGNorm"
    }
  },
  "108": {
    "inputs": {
      "shift": 3,
      "model": [
        "117",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "109": {
    "inputs": {
      "samples": [
        "110",
        0
      ],
      "vae": [
        "111",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "110": {
    "inputs": {
      "seed": 943101346007827,
      "steps": 10,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "107",
        0
      ],
      "positive": [
        "120",
        0
      ],
      "negative": [
        "122",
        0
      ],
      "latent_image": [
        "118",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "111": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "112": {
    "inputs": {
      "clip_name": "qwen/qwen_2.5_vl_7b.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "114": {
    "inputs": {
      "images": [
        "109",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "115": {
    "inputs": {
      "unet_name": "Qwen-Image-Edit-2511-FP8_e4m3fn.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "116": {
    "inputs": {
      "lora_name": "È´òÊñØÊ≥ºÊ∫Ö-Sharp.safetensors",
      "strength_model": 1,
      "model": [
        "115",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "117": {
    "inputs": {
      "lora_name": "Qwen-Image-Edit-2511-Lightning-4steps-V1.0-bf16.safetensors",
      "strength_model": 1,
      "model": [
        "116",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "118": {
    "inputs": {
      "pixels": [
        "125",
        0
      ],
      "vae": [
        "111",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "119": {
    "inputs": {
      "prompt": "È´òÊñØÊ≥ºÊ∫Ö,ÂèÇËÄÉÂõæ2ÁöÑÂú∫ÊôØÂõæÔºå‰øÆÂ§çÂõæ1ÁöÑÂú∫ÊôØÂõæÈÄèËßÜÂπ∂‰øÆÂ§çÁ©∫ÁôΩÂå∫Âüü",
      "clip": [
        "112",
        0
      ],
      "vae": [
        "111",
        0
      ],
      "image1": [
        "125",
        0
      ],
      "image2": [
        "123",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus"
    }
  },
  "120": {
    "inputs": {
      "reference_latents_method": "index_timestep_zero",
      "conditioning": [
        "119",
        0
      ]
    },
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "_meta": {
      "title": "Edit Model Reference Method"
    }
  },
  "121": {
    "inputs": {
      "prompt": "",
      "clip": [
        "112",
        0
      ],
      "vae": [
        "111",
        0
      ],
      "image1": [
        "125",
        0
      ],
      "image2": [
        "123",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus"
    }
  },
  "122": {
    "inputs": {
      "reference_latents_method": "index_timestep_zero",
      "conditioning": [
        "121",
        0
      ]
    },
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "_meta": {
      "title": "Edit Model Reference Method"
    }
  },
  "123": {
    "inputs": {
      "upscale_method": "lanczos",
      "megapixels": 1,
      "resolution_steps": 1,
      "image": [
        "102",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "Scale Image to Total Pixels"
    }
  },
  "125": {
    "inputs": {
      "upscale_method": "lanczos",
      "megapixels": 1,
      "resolution_steps": 1,
      "image": [
        "152",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "Scale Image to Total Pixels"
    }
  },
  "127": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "109",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "143": {
    "inputs": {
      "device": "auto",
      "checkpoint_path": ""
    },
    "class_type": "LoadSharpModel",
    "_meta": {
      "title": "Load SHARP Model"
    }
  },
  "144": {
    "inputs": {
      "focal_length_mm": 0,
      "output_prefix": "sharp",
      "model": [
        "143",
        0
      ],
      "image": [
        "164",
        0
      ]
    },
    "class_type": "SharpPredict",
    "_meta": {
      "title": "SHARP Predict (Image to PLY)"
    }
  },
  "150": {
    "inputs": {
      "rgthree_comparer": {
        "images": [
          {
            "name": "A",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_bceym_00003_.png&type=temp&subfolder=&rand=0.5579502752564266"
          },
          {
            "name": "B",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_bceym_00004_.png&type=temp&subfolder=&rand=0.4231993044562581"
          }
        ]
      },
      "image_a": [
        "109",
        0
      ],
      "image_b": [
        "125",
        0
      ]
    },
    "class_type": "Image Comparer (rgthree)",
    "_meta": {
      "title": "Image Comparer (rgthree)"
    }
  },
  "151": {
    "inputs": {
      "images": [
        "152",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "152": {
    "inputs": {
      "preview_gaussian_v2": "",
      "ply_path": [
        "144",
        0
      ],
      "extrinsics": [
        "144",
        1
      ],
      "intrinsics": [
        "144",
        2
      ]
    },
    "class_type": "GaussianViewer",
    "_meta": {
      "title": "GaussianViewer"
    }
  },
  "153": {
    "inputs": {
      "font_file": "Alibaba-PuHuiTi-Heavy.ttf",
      "font_size": 40,
      "border": 8,
      "color_theme": "light",
      "reel_1": [
        "155",
        0
      ]
    },
    "class_type": "LayerUtility: ImageReelComposit",
    "_meta": {
      "title": "LayerUtility: Image Reel Composit"
    }
  },
  "154": {
    "inputs": {
      "images": [
        "153",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "155": {
    "inputs": {
      "image1_text": "original",
      "image2_text": "2511",
      "image3_text": "2509",
      "image4_text": "lora-20",
      "reel_height": 1024,
      "border": 32,
      "image1": [
        "123",
        0
      ],
      "image2": [
        "109",
        0
      ],
      "image3": [
        "157",
        0
      ]
    },
    "class_type": "LayerUtility: ImageReel",
    "_meta": {
      "title": "LayerUtility: Image Reel"
    }
  },
  "156": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "157",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "157": {
    "inputs": {
      "positive_prompt": "È´òÊñØÊ≥ºÊ∫Ö,ÂèÇËÄÉÂõæ2ÁöÑÂú∫ÊôØÂõæÔºå‰øÆÂ§çÂõæ1ÁöÑÂú∫ÊôØÂõæÈÄèËßÜÂπ∂‰øÆÂ§çÁ©∫ÁôΩÂå∫Âüü",
      "negative_prompt": "",
      "generation_mode": "ÂõæÁîüÂõæ image-to-image",
      "batch_size": 1,
      "width": 1472,
      "height": 1104,
      "seed": 400191010403490,
      "steps": 8,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "auraflow_shift": 3,
      "cfg_norm_strength": 1,
      "enable_clean_gpu_memory": false,
      "enable_clean_cpu_memory_after_finish": false,
      "enable_sound_notification": false,
      "auto_save_output_folder": "",
      "output_filename_prefix": "auto_save",
      "instruction": "Describe the key features of the input image (color, shape, size, texture, objects, background), then explain how the user's text instruction should alter or modify the image. Generate a new image that meets the user's requirements while maintaining consistency with the original input where appropriate.",
      "model": [
        "163",
        0
      ],
      "clip": [
        "161",
        0
      ],
      "vae": [
        "160",
        0
      ],
      "image1": [
        "125",
        0
      ],
      "image2": [
        "123",
        0
      ]
    },
    "class_type": "QwenImageIntegratedKSampler",
    "_meta": {
      "title": "üêã Qwen Image Integrated KSampler - Github:Ôπ´luguoli"
    }
  },
  "158": {
    "inputs": {
      "lora_name": "Qwen-Image-Lightning-8steps-V1.1.safetensors",
      "strength_model": 1,
      "model": [
        "159",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "159": {
    "inputs": {
      "unet_name": "qwen_image_edit_2509_fp8_e4m3fn.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "160": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "161": {
    "inputs": {
      "clip_name": "qwen/qwen_2.5_vl_7b.safetensors",
      "type": "stable_diffusion",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "162": {
    "inputs": {
      "rgthree_comparer": {
        "images": [
          {
            "name": "A",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_lssqi_00003_.png&type=temp&subfolder=&rand=0.37451726434541655"
          },
          {
            "name": "B",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_lssqi_00004_.png&type=temp&subfolder=&rand=0.1027209523864061"
          }
        ]
      },
      "image_a": [
        "157",
        0
      ],
      "image_b": [
        "125",
        0
      ]
    },
    "class_type": "Image Comparer (rgthree)",
    "_meta": {
      "title": "Image Comparer (rgthree)"
    }
  },
  "163": {
    "inputs": {
      "lora_name": "È´òÊñØÊ≥ºÊ∫Ö-Sharp.safetensors",
      "strength_model": 1,
      "model": [
        "158",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "164": {
    "inputs": {
      "upscale_method": "lanczos",
      "megapixels": 1,
      "resolution_steps": 1,
      "image": [
        "102",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "Scale Image to Total Pixels"
    }
  }
}